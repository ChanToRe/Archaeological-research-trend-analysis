{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0f88c6",
   "metadata": {},
   "source": [
    "## 고고학 연구동향 연구(가제)\n",
    "* [DBpia-Crawler](https://github.com/ChanToRe/DBpia-Crawler)를 통해 수집된 고고학 논문을 분석하여 2000년 이후 고고학 연구 동향을 살핌\n",
    "* 워드클라우드 시각화 기법과 토픽 모델링 기법을 활용하여 연구동향을 분석\n",
    "\n",
    "### 설치\n",
    "```bash\n",
    "pip install tqdm\n",
    "pip install pandas\n",
    "pip install matplotlib\n",
    "pip install konlpy\n",
    "pip install wordcloud\n",
    "```\n",
    "\n",
    "### 진행\n",
    "1. 크롤러 개발 (2022/01/26 완료)\n",
    "2. 데이터 체크 및 한자 번역 (2022/01/31 완료)\n",
    "3. 명사 추출 및 빈도 체크 (2022/02/01 완료) \n",
    "4. 워드 클라우드 적용 확인 (2022/02/02 완료)\n",
    "5. 불용어 사전, 고유명사 사전 제작 (2022/02/04 진행중~) [#1](https://github.com/ChanToRe/Archaeological-research-trend-analysis/issues/1#issue-1123805974) 참조\n",
    "6. Okt -> Mecab 전환 (2022/02/05 완료)\n",
    "7. 사회 연결망 분석 구현(2022/02/07 완료)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57de3c-b976-4631-a37b-aa0c34ff9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import hanja\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "from konlpy.tag import Mecab\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051ab80-831f-4557-8b2c-d3c06c8778b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로드 & 한글 깨짐 방지\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "data = pd.read_csv('./Data-before.csv')\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa76804-9cc1-495c-b43b-d866435587c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#제목 한자 번역\n",
    "before_title = df[['title']] #제목 추출\n",
    "list_before_title = before_title.values.tolist() #제목 리스트화\n",
    "after_title = [] #번역 후 제목 리스트\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(list_before_title))):\n",
    "    trans = hanja.translate(list_before_title[i], \"substitution\")\n",
    "    after_title.append(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a25741",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_result = df.assign(translate_title = after_title)\n",
    "DB = pd.DataFrame(trans_result)\n",
    "sort_DB = DB.sort_values(by=['date'])\n",
    "#DB.to_excel(\"~/Desktop/result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#고고학 논문 발간 수 그래프\n",
    "sort_DB[\"date\"].value_counts().sort_index().plot(kind='bar')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.title(\"고고학 논문 발간 수\", fontsize=20)\n",
    "plt.xlabel(\"연도\", fontsize=20)\n",
    "plt.ylabel(\"수량\", fontsize=20)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e358b0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mecab 생성\n",
    "mecab = Mecab()\n",
    "wc = WordCloud(width=1000, height=1000, random_state=0, max_words=50, max_font_size=300 ,background_color=\"white\", font_path=r'~/Library/Fonts/AppleGothic.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 처리\n",
    "def clean_text(row):\n",
    "    text = row['translate_title']\n",
    "    txt = re.sub('[a-zA-z]','',text)\n",
    "    txxt = re.sub('[^가-힣a-z]', ' ', txt)\n",
    "    text = mecab.morphs(txxt)\n",
    "    stopwords_path = \"/Users/jch/Desktop/stopword.txt\"\n",
    "    with open(stopwords_path, encoding='UTF-8') as file:\n",
    "        stopwords = file.readlines()\n",
    "    stopwords = [x.strip() for x in stopwords]\n",
    "    text = [t for t in text if t not in stopwords]\n",
    "    return text\n",
    "\n",
    "trans_result['translate_title'] = trans_result.apply(clean_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f2eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#분기별 구분\n",
    "date_trash = trans_result[trans_result['date'] < 2000] #2000년대 이전\n",
    "\n",
    "#2000년대 발간 논문\n",
    "date_zero = trans_result[(trans_result['date'] >= 2000) & (trans_result['date'] < 2010)]\n",
    "date_zero_nx = trans_result[(trans_result['date'] >= 2000) & (trans_result['date'] < 2010)]\n",
    "date_zero_title = pd.DataFrame(date_zero['translate_title'])\n",
    "date_zero_title.to_csv(\"./date_zero_title.csv\", sep = \"\\t\", index=False)\n",
    "zero = open(\"./date_zero_title.csv\", 'r', encoding=\"UTF-8\")\n",
    "data_zero = zero.read()\n",
    "zero.close()\n",
    "\n",
    "#2010년대 발간 논문\n",
    "date_ten = trans_result[(trans_result['date'] >= 2010) & (trans_result['date'] < 2020)]\n",
    "date_ten_nx = trans_result[(trans_result['date'] >= 2010) & (trans_result['date'] < 2020)] \n",
    "date_ten_title = pd.DataFrame(date_ten['translate_title'])\n",
    "date_ten_title.to_csv(\"./date_ten_title.csv\", sep = \"\\t\", index=False)\n",
    "ten = open(\"./date_ten_title.csv\", 'r', encoding=\"UTF-8\")\n",
    "data_ten = ten.read()\n",
    "ten.close()\n",
    "\n",
    "#2020년대 발간 논문\n",
    "date_twenty = trans_result[trans_result['date'] > 2019]\n",
    "date_twenty_nx = trans_result[trans_result['date'] > 2019] \n",
    "date_twenty_title = pd.DataFrame(date_twenty['translate_title'])\n",
    "date_twenty_title.to_csv(\"./date_twenty_title.csv\", sep = \"\\t\", index=False)\n",
    "twenty = open(\"./date_twenty_title.csv\", 'r', encoding=\"UTF-8\")\n",
    "data_twenty = twenty.read()\n",
    "twenty.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#발간 논문 명사 빈도 카운트(워드클라우드)\n",
    "def noun_count(data):\n",
    "    noun = mecab.nouns(data)\n",
    "    count = Counter(noun)\n",
    "    noun_list = count.most_common(50)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(wc.generate_from_frequencies(dict(noun_list)))\n",
    "\n",
    "#네트워크 분석 수행 모듈\n",
    "def network_analysis(date_nx):\n",
    "    G = nx.Graph()\n",
    "    edge_list = []\n",
    "\n",
    "    for trans_dict in date_nx['translate_title']:\n",
    "        trans = list(trans_dict)\n",
    "        num_trans = len(trans)\n",
    "        if num_trans > 0 :\n",
    "            for j in range(num_trans-1):\n",
    "                for k in range(j+1, num_trans):\n",
    "                    edge_list += [tuple(sorted([trans[j], trans[k]]))]\n",
    "    edges = list(Counter(edge_list).items())\n",
    "\n",
    "    G = nx.Graph((x, y, {'weight': v}) for (x, y), v in edges)\n",
    "\n",
    "    font_path='/Users/jch/Library/Fonts/AppleGothic.ttf'\n",
    "    font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "    return G\n",
    "\n",
    "#네트워크 분석 그래프 모듈\n",
    "def network_graph(G):\n",
    "\n",
    "    nx.Graph()\n",
    "\n",
    "    pr = nx.pagerank(G)\n",
    "    nsize = np.array([v for v in pr.values()])\n",
    "    nsize = 2000 * (nsize - min(nsize)) / (max(nsize) - min(nsize))\n",
    "\n",
    "    plt.figure(figsize=(80,80))\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos,\n",
    "                    node_shape = \"o\",\n",
    "                    node_color=range(len(G)),\n",
    "                    cmap=plt.cm.Blues_r,\n",
    "                    node_size=25 * nsize)\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos,\n",
    "                    style='solid',\n",
    "                    width=5,\n",
    "                    alpha=0.1,\n",
    "                    edge_color='#808080')\n",
    "\n",
    "    nx.draw_networkx_labels(G, pos,\n",
    "                    font_size=20,\n",
    "                    font_family=font_name)\n",
    "    plt.show()\n",
    "\n",
    "#연결중심성\n",
    "def bet_centratlity(data, end):\n",
    "    bet_cen = nx.betweenness_centrality(data)\n",
    "    result = sorted(bet_cen.items(), key=lambda x:x[1], reverse=True)[0:end]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84da438",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e135bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_zero = network_analysis(date_zero_nx)\n",
    "network_graph(G_zero)\n",
    "\n",
    "noun_count(data_zero)\n",
    "    \n",
    "bet_centratlity(G_zero, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
