{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0f88c6",
   "metadata": {},
   "source": [
    "## 고고학 연구동향 연구(가제)\n",
    "* [DBpia-Crawler](https://github.com/ChanToRe/DBpia-Crawler)를 통해 수집된 고고학 논문을 분석하여 2000년 이후 고고학 연구 동향을 살핌\n",
    "* 워드클라우드 시각화, 사회연결망 분석, 토픽 모델링을 활용하여 2000년 이후의 고고학 연구동향을 연구\n",
    "\n",
    "### 진행\n",
    "1. 크롤러 개발 (2022/01/26 완료)\n",
    "2. 데이터 체크 및 한자 번역 (2022/01/31 완료)\n",
    "3. 명사 추출 및 빈도 체크 (2022/02/01 완료) \n",
    "4. 워드 클라우드 적용 확인 (2022/02/02 완료)\n",
    "5. 불용어 사전, 고유명사 사전 제작 (2022/02/04 진행중~) [#1](https://github.com/ChanToRe/Archaeological-research-trend-analysis/issues/1#issue-1123805974) 참조\n",
    "6. Okt -> Mecab 전환 (2022/02/05 완료)\n",
    "7. 사회 연결망 분석 구현(2022/02/07 완료)\n",
    "8. 토픽 모델링 모델 구현(2022/02/10 완료)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57de3c-b976-4631-a37b-aa0c34ff9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import hanja\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "from konlpy.tag import Mecab\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.callbacks import CoherenceMetric\n",
    "from gensim import corpora\n",
    "from gensim.models.callbacks import PerplexityMetric\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import pickle\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051ab80-831f-4557-8b2c-d3c06c8778b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로드 & 한글 깨짐 방지\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "data = pd.read_csv('./Data-before.csv')\n",
    "before_df = pd.DataFrame(data)\n",
    "before_df[\"Full-Data\"] = before_df[\"translate_title\"] + \" \" + before_df[\"Abstract\"]\n",
    "before_df.dropna(subset=['Abstract'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa76804-9cc1-495c-b43b-d866435587c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한자 번역\n",
    "before_title = before_df[['Full-Data']] #분석 대상 데이터 추출\n",
    "list_before_title = before_title.values.tolist() #분석 대상 데이터 리스트화\n",
    "after_title = [] #한자 번역 후 리스트\n",
    "\n",
    "for i in tqdm(range(len(list_before_title))):\n",
    "    trans = hanja.translate(list_before_title[i], \"substitution\")\n",
    "    after_title.append(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a25741",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_result = before_df.assign(translate_title = after_title)\n",
    "DB = pd.DataFrame(trans_result)\n",
    "sort_DB = DB.sort_values(by=['date'])\n",
    "#DB.to_excel(\"~/Desktop/result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#고고학 논문 발간 수 바 그래프\n",
    "sort_DB[\"date\"].value_counts().sort_index().plot(kind='bar')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.title(\"고고학 논문 발간 수\", fontsize=20)\n",
    "plt.xlabel(\"연도\", fontsize=20)\n",
    "plt.ylabel(\"수량\", fontsize=20)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e358b0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mecab 생성\n",
    "mecab = Mecab()\n",
    "\n",
    "#WordCloud 생성\n",
    "wc = WordCloud(width=1000, height=1000, random_state=0, max_words=50, max_font_size=300 ,background_color=\"white\", font_path=r'./NanumGothicBold.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 처리\n",
    "def clean_text(row):\n",
    "    text = row['Full-Data']\n",
    "    txt = re.sub('[a-zA-z]','',text) #영어 제거\n",
    "    txxt = re.sub('[^가-힣a-z]', ' ', txt)\n",
    "    text = mecab.morphs(txxt)\n",
    "    stopwords_path = \"./stopword.txt\"\n",
    "    with open(stopwords_path, encoding='UTF-8') as file:\n",
    "        stopwords = file.readlines()\n",
    "    stopwords = [x.strip() for x in stopwords]\n",
    "    text = [t for t in text if t not in stopwords]\n",
    "    return text\n",
    "\n",
    "trans_result['Full-Data'] = trans_result.apply(clean_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f2eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#분기별 구분\n",
    "date_trash = trans_result[trans_result['date'] < 2000] #2000년대 이전\n",
    "\n",
    "#2000년대 발간 논문\n",
    "date_zero = trans_result[(trans_result['date'] >= 2000) & (trans_result['date'] < 2010)]\n",
    "date_zero_nx = trans_result[(trans_result['date'] >= 2000) & (trans_result['date'] < 2010)]\n",
    "date_zero_title = pd.DataFrame(date_zero['Full-Data'])\n",
    "date_zero_title.to_csv(\"./date_zero_title.csv\", sep = \"\\t\", index=False)\n",
    "zero = open(\"./date_zero_title.csv\", 'r', encoding=\"UTF-8\")\n",
    "data_zero = zero.read()\n",
    "zero.close()\n",
    "\n",
    "#2010년대 발간 논문\n",
    "date_ten = trans_result[(trans_result['date'] >= 2010) & (trans_result['date'] < 2020)]\n",
    "date_ten_nx = trans_result[(trans_result['date'] >= 2010) & (trans_result['date'] < 2020)] \n",
    "date_ten_title = pd.DataFrame(date_ten['Full-Data'])\n",
    "date_ten_title.to_csv(\"./date_ten_title.csv\", sep = \"\\t\", index=False)\n",
    "ten = open(\"./date_ten_title.csv\", 'r', encoding=\"UTF-8\")\n",
    "data_ten = ten.read()\n",
    "ten.close()\n",
    "\n",
    "#2020년대 발간 논문\n",
    "date_twenty = trans_result[trans_result['date'] > 2019]\n",
    "date_twenty_nx = trans_result[trans_result['date'] > 2019] \n",
    "date_twenty_title = pd.DataFrame(date_twenty['Full-Data'])\n",
    "date_twenty_title.to_csv(\"./date_twenty_title.csv\", sep = \"\\t\", index=False)\n",
    "twenty = open(\"./date_twenty_title.csv\", 'r', encoding=\"UTF-8\")\n",
    "data_twenty = twenty.read()\n",
    "twenty.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#발간 논문 명사 빈도 카운트(워드클라우드)\n",
    "def noun_count(data):\n",
    "    noun = mecab.nouns(data)\n",
    "    count = Counter(noun)\n",
    "    noun_list = count.most_common(50)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(wc.generate_from_frequencies(dict(noun_list)))\n",
    "\n",
    "#네트워크 분석 수행 모듈\n",
    "def network_analysis(date_nx):\n",
    "    G = nx.Graph()\n",
    "    edge_list = []\n",
    "\n",
    "    for trans_dict in date_nx['Full-Data']:\n",
    "        trans = list(trans_dict)\n",
    "        num_trans = len(trans)\n",
    "        if num_trans > 0 :\n",
    "            for j in range(num_trans-1):\n",
    "                for k in range(j+1, num_trans):\n",
    "                    edge_list += [tuple(sorted([trans[j], trans[k]]))]\n",
    "    edges = list(Counter(edge_list).items())\n",
    "\n",
    "    G = nx.Graph((x, y, {'weight': v}) for (x, y), v in edges)\n",
    "\n",
    "    font_path='./NanumGothicBold.ttf'\n",
    "    font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "    return G\n",
    "\n",
    "#네트워크 분석 그래프 모듈\n",
    "def network_graph(G):\n",
    "\n",
    "    nx.Graph()\n",
    "\n",
    "    pr = nx.pagerank(G)\n",
    "    nsize = np.array([v for v in pr.values()])\n",
    "    nsize = 2000 * (nsize - min(nsize)) / (max(nsize) - min(nsize))\n",
    "\n",
    "    plt.figure(figsize=(80,80))\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "    font_path='./NanumGothicBold.ttf'\n",
    "    font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos,\n",
    "                    node_shape = \"o\",\n",
    "                    node_color=range(len(G)),\n",
    "                    cmap=plt.cm.Blues_r,\n",
    "                    node_size=25 * nsize)\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos,\n",
    "                    style='solid',\n",
    "                    width=5,\n",
    "                    alpha=0.1,\n",
    "                    edge_color='#808080')\n",
    "\n",
    "    nx.draw_networkx_labels(G, pos,\n",
    "                    font_size=20,\n",
    "                    font_family=font_name)\n",
    "    plt.show()\n",
    "\n",
    "#연결중심성\n",
    "def bet_centratlity(data, end):\n",
    "    bet_cen = nx.betweenness_centrality(data)\n",
    "    result = sorted(bet_cen.items(), key=lambda x:x[1], reverse=True)[0:end]\n",
    "    return result\n",
    "\n",
    "#토픽모델링\n",
    "def LDA_topic(Topic_data, chunksize, iterations, num_topics, passes, eval_every, year) :\n",
    "    savename = ('%d' + 'Topic.html') %year\n",
    "    data_dic = Topic_data.values.tolist()\n",
    "    dictionary = corpora.Dictionary(data_dic)\n",
    "    corpus = [dictionary.doc2bow(text) for text in data_dic]\n",
    "    \n",
    "    temp = dictionary[0]\n",
    "\n",
    "    LDA_model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary.id2token,\n",
    "        chunksize=chunksize, #트레이닝 1회당 처리할 문서 갯수\n",
    "        alpha='auto',\n",
    "        eta='auto',\n",
    "        iterations=iterations, #문서당 반복 횟수\n",
    "        num_topics=num_topics,  #생성 토픽 갯수\n",
    "        passes=passes, #전체 Corpus 트레이닝 횟수\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "    top_topics = LDA_model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "    avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "    #print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "    \n",
    "    lda_visualization = gensimvis.prepare(LDA_model, corpus, dictionary, sort_topics=False)\n",
    "    pyLDAvis.save_html(lda_visualization, savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84da438",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84613477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2000년대 발간 학술 논문 분석\n",
    "\n",
    "#네트워크 분석 출력\n",
    "G_zero = network_analysis(date_zero_nx)\n",
    "network_graph(G_zero)\n",
    "\n",
    "#연결중심성 출력\n",
    "bet_centratlity(G_zero, 10)\n",
    "\n",
    "#워드클라우드 출력\n",
    "noun_count(data_zero)\n",
    "\n",
    "#토픽모델링 출력\n",
    "LDA_topic(date_zero[\"Full-Data\"], chunksize=20000, iterations=400, num_topics=5, passes=20, eval_every=None, year=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bbd7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2010년대 발간 학술 논문 분석\n",
    "\n",
    "#네트워크 분석 출력\n",
    "G_ten = network_analysis(date_ten_nx)\n",
    "network_graph(G_ten)\n",
    "\n",
    "#연결중심성 출력\n",
    "bet_centratlity(G_ten, 10)\n",
    "\n",
    "#워드클라우드 출력\n",
    "noun_count(data_ten)\n",
    "\n",
    "#토픽모델링 출력\n",
    "LDA_topic(date_ten[\"Full-Data\"], chunksize=20000, iterations=400, num_topics=8, passes=20, eval_every=None, year=2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e135bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020년대 발간 학술 논문 분석\n",
    "\n",
    "#네트워크 분석 출력\n",
    "G_twenty = network_analysis(date_twenty_nx)\n",
    "network_graph(G_twenty)\n",
    "\n",
    "#연결중심성 출력\n",
    "bet_centratlity(G_twenty, 10)\n",
    "\n",
    "#워드클라우드 출력\n",
    "noun_count(data_twenty)\n",
    "\n",
    "#토픽모델링 출력\n",
    "LDA_topic(date_twenty[\"Full-Data\"], chunksize=20000, iterations=400, num_topics=5, passes=20, eval_every=None, year=2020)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
